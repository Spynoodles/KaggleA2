{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression Ratio (ρ): 0.1990642361111111\n",
      "MSE1:5.092339583333334,MSE2:35.81712777777778\n",
      "SCORE:80.72231458333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(40.90946736111111),\n",
       " 0.1990642361111111,\n",
       " np.float64(80.72231458333333))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "\n",
    "# Step 2: Calculate frequency of each coefficient\n",
    "def calculate_frequency(data):\n",
    "    frequency = defaultdict(int)\n",
    "    for value in data.ravel():\n",
    "        frequency[value] += 1\n",
    "    return frequency\n",
    "\n",
    "# Step 3: Huffman Tree and Encoding (reuse from your code)\n",
    "class HuffmanNode:\n",
    "    def __init__(self, value, frequency):\n",
    "        self.value = value\n",
    "        self.frequency = frequency\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.frequency < other.frequency\n",
    "\n",
    "def build_huffman_tree(frequency):\n",
    "    priority_queue = [HuffmanNode(value, freq) for value, freq in frequency.items()]\n",
    "    heapq.heapify(priority_queue)\n",
    "\n",
    "    while len(priority_queue) > 1:\n",
    "        left = heapq.heappop(priority_queue)\n",
    "        right = heapq.heappop(priority_queue)\n",
    "        \n",
    "        internal_node = HuffmanNode(None, left.frequency + right.frequency)\n",
    "        internal_node.left = left\n",
    "        internal_node.right = right\n",
    "        \n",
    "        heapq.heappush(priority_queue, internal_node)\n",
    "\n",
    "    return priority_queue[0]  # Root of the tree\n",
    "\n",
    "def generate_huffman_codes(node, current_code='', codes=defaultdict(str)):\n",
    "    if node is not None:\n",
    "        if node.value is not None:\n",
    "            codes[node.value] = current_code\n",
    "        generate_huffman_codes(node.left, current_code + '0', codes)\n",
    "        generate_huffman_codes(node.right, current_code + '1', codes)\n",
    "    return codes\n",
    "\n",
    "def compress_data(data, huffman_codes):\n",
    "    compressed_data = ''.join(huffman_codes[value] for value in data.ravel())\n",
    "    return compressed_data\n",
    "\n",
    "def decompress_data(compressed_data, huffman_tree, original_shape):\n",
    "    current_node = huffman_tree\n",
    "    decompressed_data = []\n",
    "\n",
    "    for bit in compressed_data:\n",
    "        current_node = current_node.left if bit == '0' else current_node.right\n",
    "        if current_node.value is not None:\n",
    "            decompressed_data.append(current_node.value)\n",
    "            current_node = huffman_tree\n",
    "\n",
    "    return np.array(decompressed_data).reshape(original_shape)\n",
    "\n",
    "# Step 4: Apply Transform Coding\n",
    "def apply_transform(image):\n",
    "    # Apply 2D DCT on blocks of the image\n",
    "    block_size = 8\n",
    "    transformed_image = np.zeros_like(image, dtype=float)\n",
    "\n",
    "    for i in range(0, image.shape[0], block_size):\n",
    "        for j in range(0, image.shape[1], block_size):\n",
    "            block = image[i:i+block_size, j:j+block_size]\n",
    "            dct_block = cv2.dct(np.float32(block))\n",
    "            transformed_image[i:i+block_size, j:j+block_size] = dct_block\n",
    "\n",
    "    return transformed_image\n",
    "\n",
    "# Step 5: Quantize the DCT coefficients\n",
    "# Step 5: Quantize the DCT coefficients block-wise\n",
    "def quantize_dct(dct_image, quantization_matrix):\n",
    "    block_size = quantization_matrix.shape[0]\n",
    "    quantized_image = np.zeros_like(dct_image, dtype=int)\n",
    "\n",
    "    for i in range(0, dct_image.shape[0], block_size):\n",
    "        for j in range(0, dct_image.shape[1], block_size):\n",
    "            block = dct_image[i:i+block_size, j:j+block_size]\n",
    "            quantized_image[i:i+block_size, j:j+block_size] = np.round(block / quantization_matrix)\n",
    "    \n",
    "    return quantized_image\n",
    "\n",
    "# Step 6: Dequantize the DCT coefficients block-wise\n",
    "def dequantize_dct(quantized_image, quantization_matrix):\n",
    "    block_size = quantization_matrix.shape[0]\n",
    "    dequantized_image = np.zeros_like(quantized_image, dtype=float)\n",
    "\n",
    "    for i in range(0, quantized_image.shape[0], block_size):\n",
    "        for j in range(0, quantized_image.shape[1], block_size):\n",
    "            block = quantized_image[i:i+block_size, j:j+block_size]\n",
    "            dequantized_image[i:i+block_size, j:j+block_size] = block * quantization_matrix\n",
    "    \n",
    "    return dequantized_image\n",
    "\n",
    "# Step 6: Apply inverse DCT to reconstruct the image\n",
    "def apply_inverse_transform(dct_image):\n",
    "    block_size = 8\n",
    "    reconstructed_image = np.zeros_like(dct_image, dtype=float)\n",
    "\n",
    "    for i in range(0, dct_image.shape[0], block_size):\n",
    "        for j in range(0, dct_image.shape[1], block_size):\n",
    "            block = dct_image[i:i+block_size, j:j+block_size]\n",
    "            idct_block = cv2.idct(np.float32(block))\n",
    "            reconstructed_image[i:i+block_size, j:j+block_size] = idct_block\n",
    "\n",
    "    return np.clip(reconstructed_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Step 7: Process the Image\n",
    "def process_transform(image_path, quantization_matrix):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Apply DCT\n",
    "    transformed_image = apply_transform(image)\n",
    "    \n",
    "    # Quantize DCT coefficients\n",
    "    quantized_image = quantize_dct(transformed_image, quantization_matrix)\n",
    "    \n",
    "    # Flatten and calculate frequency\n",
    "    frequency = calculate_frequency(quantized_image)\n",
    "    \n",
    "    # Build Huffman Tree and generate codes\n",
    "    huffman_tree = build_huffman_tree(frequency)\n",
    "    huffman_codes = generate_huffman_codes(huffman_tree)\n",
    "    \n",
    "    # Compress\n",
    "    compressed_data = compress_data(quantized_image, huffman_codes)\n",
    "    \n",
    "    # Decompress and reconstruct\n",
    "    decompressed_quantized_image = decompress_data(compressed_data, huffman_tree, quantized_image.shape)\n",
    "    dequantized_image = dequantize_dct(decompressed_quantized_image, quantization_matrix)\n",
    "    reconstructed_image = apply_inverse_transform(dequantized_image)\n",
    "    \n",
    "    return compressed_data, reconstructed_image\n",
    "\n",
    "# Step 8: Define Quantization Matrix (JPEG example)\n",
    "quantization_matrix = np.array([\n",
    "    [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "    [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "    [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "    [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "    [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "    [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "    [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "    [72, 92, 95, 98, 112, 100, 103, 99]\n",
    "])\n",
    "def calculate_metrics(original_image1, reconstructed_image1, bitstream1,\n",
    "                      original_image2, reconstructed_image2, bitstream2):\n",
    "    # Calculate MSE for both images\n",
    "    mse1 = np.mean((original_image1 - reconstructed_image1) ** 2)\n",
    "    mse2 = np.mean((original_image2 - reconstructed_image2) ** 2)\n",
    "    SUM = mse1 + mse2\n",
    "    \n",
    "    # Calculate compression ratio (ρ)\n",
    "    total_bits_original = 2 * 1200 * 1200 * 8\n",
    "    total_bits_compressed = len(bitstream1)+len(bitstream2)\n",
    "    rho = total_bits_compressed / total_bits_original\n",
    "    \n",
    "    # Combined score\n",
    "    score = SUM + (200 * rho)\n",
    "    \n",
    "    # print(f\"Compressed Bits (Image1): {sum(len(chunk) for chunk in bitstream1)}\")\n",
    "    # print(f\"Compressed Bits (Image2): {sum(len(chunk) for chunk in bitstream2)}\")\n",
    "    # print(f\"Original Bits: {total_bits_original}\")\n",
    "    print(f\"Compression Ratio (ρ): {rho}\")\n",
    "    print(f\"MSE1:{mse1},MSE2:{mse2}\")\n",
    "    print(f\"SCORE:{score}\")\n",
    "    return SUM, rho, score\n",
    "# Process images\n",
    "c1, r1 = process_transform('Watermarked_Image1.tiff', quantization_matrix)\n",
    "c2, r2 = process_transform('Watermarked_Image2.tiff', quantization_matrix)\n",
    "\n",
    "# Original images\n",
    "og1 = cv2.imread('Watermarked_Image1.tiff', cv2.IMREAD_GRAYSCALE)\n",
    "og2 = cv2.imread('Watermarked_Image2.tiff', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Metrics\n",
    "calculate_metrics(og1, r1, c1, og2, r2, c2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def group(compressed_data):\n",
    "    byte_data = []\n",
    "    for i in range(0, len(compressed_data), 8):\n",
    "        byte_data.append(compressed_data[i:i+8])\n",
    "    return byte_data\n",
    "\n",
    "bitstreamimage1=group(c1)\n",
    "bitstreamimage2=group(c2)\n",
    "size1=1200*1200-len(bitstreamimage1)\n",
    "size2=1200*1200-len(bitstreamimage2)\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "\"ID\": list(range(1200*1200)),\n",
    "\"CompressedImage1\": np.array(bitstreamimage1+([\"I\"]*size1)),\n",
    "    \"CompressedImage2\":  np.array(bitstreamimage2+([\"I\"]*size2)),\n",
    "    \"Image1\": np.array(r1).flatten(),\n",
    "    \"Image2\": np.array(r2).flatten(),} )\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "katana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
